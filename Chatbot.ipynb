{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750bea5c-238f-4f78-9e0b-9edf97cc8c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import faiss  # Vector Database\n",
    "    import PyPDF2  # PDF Upload and Processing\n",
    "    from sentence_transformers import SentenceTransformer  # Domain-Specific Embeddings\n",
    "    ADVANCED_MODE = True\n",
    "    print(\"Advanced RAG mode enabled with Faiss, PDF processing, and embeddings\")\n",
    "except ImportError:\n",
    "    ADVANCED_MODE = False\n",
    "    print(\"Basic mode - install faiss-cpu, PyPDF2, sentence-transformers for advanced features\")\n",
    "\n",
    "class EnhancedRAGAssistant:\n",
    "    def __init__(self, use_embeddings: bool = True):\n",
    "        \"\"\"Initialize assistant with enhanced RAG capabilities\"\"\"\n",
    "        self.use_embeddings = use_embeddings and ADVANCED_MODE\n",
    "        self.knowledge_base = []\n",
    "        self.conversation_history = []\n",
    "        \n",
    "        # NEW: Embedding Creation & Domain-Specific Embeddings\n",
    "        if self.use_embeddings:\n",
    "            print(\"Loading domain-specific mental health embeddings model...\")\n",
    "            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "            self.embedding_dim = 384\n",
    "            \n",
    "            # NEW: Faiss Vector Database\n",
    "            self.vector_index = faiss.IndexFlatIP(self.embedding_dim)  # Inner product for similarity\n",
    "            self.doc_embeddings = []\n",
    "            \n",
    "        self.cache_file = \"mental_health_embeddings_cache.pkl\"\n",
    "        self.vector_cache_file = \"mental_health_vector_cache.faiss\"\n",
    "        \n",
    "        self.create_knowledge_base()\n",
    "        \n",
    "        self.load_cached_embeddings()\n",
    "        \n",
    "        print(f\"Mental Health Assistant initialized with {len(self.knowledge_base)} documents\")\n",
    "        if self.use_embeddings:\n",
    "            print(f\"Vector database contains {self.vector_index.ntotal} embeddings\")\n",
    "\n",
    "    def create_knowledge_base(self) -> None:\n",
    "        \"\"\"Create enhanced knowledge base with mental health information\"\"\"\n",
    "        # Original knowledge base + enhanced content\n",
    "        knowledge_docs = [\n",
    "            {\n",
    "                \"id\": \"anxiety_basics\",\n",
    "                \"content\": \"anxiety worry panic breathing relaxation mindfulness exercise sleep routine calm techniques deep breath meditation progressive muscle\",\n",
    "                \"full_text\": \"For anxiety: Practice deep breathing (4-7-8 technique), try progressive muscle relaxation, use mindfulness meditation, maintain regular exercise, keep consistent sleep schedule, limit caffeine, and stay connected with support system.\",\n",
    "                \"category\": \"anxiety\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"anxiety_advanced\",\n",
    "                \"content\": \"anxiety cognitive behavioral therapy CBT exposure therapy grounding techniques 5-4-3-2-1 method panic attacks agoraphobia social anxiety generalized anxiety disorder GAD\",\n",
    "                \"full_text\": \"Advanced anxiety management: Cognitive Behavioral Therapy (CBT) helps identify and change negative thought patterns. Exposure therapy gradually reduces avoidance behaviors. Use grounding techniques like 5-4-3-2-1 method (5 things you see, 4 you touch, 3 you hear, 2 you smell, 1 you taste). Different types include panic disorder, social anxiety, and GAD.\",\n",
    "                \"category\": \"anxiety\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"depression_basics\",\n",
    "                \"content\": \"depression sad hopeless routine goals exercise sunlight sleep self-care activities support connection therapy medication\",\n",
    "                \"full_text\": \"For depression: Maintain daily routine, set small achievable goals, stay physically active, get sunlight exposure, practice self-compassion, stay connected with others, engage in previously enjoyed activities. Professional therapy and medication are highly effective.\",\n",
    "                \"category\": \"depression\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"depression_advanced\",\n",
    "                \"content\": \"depression major depressive disorder MDD seasonal affective disorder SAD bipolar disorder therapy antidepressants SSRI cognitive therapy behavioral activation\",\n",
    "                \"full_text\": \"Depression types and treatments: Major Depressive Disorder (MDD) affects mood, energy, and daily functioning. Seasonal Affective Disorder (SAD) occurs during darker months. Treatment includes therapy (cognitive, behavioral activation), medications (SSRIs, SNRIs), and lifestyle changes. Bipolar disorder requires specialized treatment.\",\n",
    "                \"category\": \"depression\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"stress_management\",\n",
    "                \"content\": \"stress overwhelmed pressure time management relaxation exercise healthy lifestyle social support hobbies professional help resilience\",\n",
    "                \"full_text\": \"For stress: Use time management techniques, practice relaxation methods, engage in regular physical activity, maintain healthy lifestyle, seek social support, pursue enjoyable hobbies, consider professional counseling, build resilience through positive thinking.\",\n",
    "                \"category\": \"stress\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"crisis_resources\",\n",
    "                \"content\": \"crisis suicide self-harm emergency help 988 lifeline professional immediate support therapy treatment\",\n",
    "                \"full_text\": \"Crisis resources: National Suicide Prevention Lifeline 988, Crisis Text Line (text HOME to 741741), Emergency Services 911. If having thoughts of self-harm, seek immediate professional help. Treatment is effective and help is available.\",\n",
    "                \"category\": \"crisis\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"trauma_ptsd\",\n",
    "                \"content\": \"trauma PTSD post-traumatic stress disorder flashbacks nightmares avoidance hypervigilance EMDR therapy exposure therapy\",\n",
    "                \"full_text\": \"Trauma and PTSD: Post-Traumatic Stress Disorder can develop after experiencing or witnessing traumatic events. Symptoms include flashbacks, nightmares, avoidance, and hypervigilance. Effective treatments include EMDR (Eye Movement Desensitization and Reprocessing), trauma-focused CBT, and exposure therapy.\",\n",
    "                \"category\": \"trauma\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"mindfulness_meditation\",\n",
    "                \"content\": \"mindfulness meditation present moment awareness breathing exercises body scan loving-kindness meditation apps headspace calm\",\n",
    "                \"full_text\": \"Mindfulness and meditation: Practice present-moment awareness through breathing exercises, body scans, and loving-kindness meditation. Regular practice reduces stress, anxiety, and depression. Use apps like Headspace, Calm, or Insight Timer for guided sessions. Start with 5-10 minutes daily.\",\n",
    "                \"category\": \"mindfulness\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        self.knowledge_base = knowledge_docs\n",
    "\n",
    "    # NEW: Document Ingestion\n",
    "    def ingest_document(self, text: str, doc_id: str, category: str = \"general\") -> None:\n",
    "        \"\"\"Ingest a new document into the knowledge base\"\"\"\n",
    "        # NEW: Chunking Strategies\n",
    "        chunks = self.chunk_document(text, chunk_size=200, overlap=50)\n",
    "        \n",
    "        for i, chunk in enumerate(chunks):\n",
    "            doc = {\n",
    "                \"id\": f\"{doc_id}_chunk_{i}\",\n",
    "                \"content\": chunk.lower(),\n",
    "                \"full_text\": chunk,\n",
    "                \"category\": category,\n",
    "                \"source\": doc_id\n",
    "            }\n",
    "            self.knowledge_base.append(doc)\n",
    "            \n",
    "            # NEW: Create embeddings for new document\n",
    "            if self.use_embeddings:\n",
    "                embedding = self.embedding_model.encode([chunk])[0]\n",
    "                self.doc_embeddings.append(embedding)\n",
    "                self.vector_index.add(np.array([embedding], dtype=np.float32))\n",
    "        \n",
    "        print(f\"Ingested document '{doc_id}' as {len(chunks)} chunks\")\n",
    "\n",
    "    # NEW: Chunking Strategies\n",
    "    def chunk_document(self, text: str, chunk_size: int = 200, overlap: int = 50) -> List[str]:\n",
    "        \"\"\"Divide document into overlapping chunks for better retrieval\"\"\"\n",
    "        words = text.split()\n",
    "        chunks = []\n",
    "        \n",
    "        for i in range(0, len(words), chunk_size - overlap):\n",
    "            chunk_words = words[i:i + chunk_size]\n",
    "            chunk = ' '.join(chunk_words)\n",
    "            if len(chunk.strip()) > 0:\n",
    "                chunks.append(chunk)\n",
    "                \n",
    "        return chunks\n",
    "\n",
    "    # NEW: PDF Upload and Processing\n",
    "    def upload_pdf(self, pdf_path: str, doc_id: Optional[str] = None) -> None:\n",
    "        \"\"\"Upload and process PDF document\"\"\"\n",
    "        if not ADVANCED_MODE:\n",
    "            print(\"PDF processing requires PyPDF2. Install with: pip install PyPDF2\")\n",
    "            return\n",
    "            \n",
    "        if doc_id is None:\n",
    "            doc_id = os.path.basename(pdf_path).replace('.pdf', '')\n",
    "            \n",
    "        try:\n",
    "            with open(pdf_path, 'rb') as file:\n",
    "                pdf_reader = PyPDF2.PdfReader(file)\n",
    "                text = \"\"\n",
    "                \n",
    "                for page in pdf_reader.pages:\n",
    "                    text += page.extract_text() + \"\\n\"\n",
    "                \n",
    "                # NEW: Divide PDF into Chunks and ingest\n",
    "                self.ingest_document(text, doc_id, \"pdf_upload\")\n",
    "                print(f\"Successfully processed PDF: {pdf_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing PDF {pdf_path}: {str(e)}\")\n",
    "\n",
    "    # NEW: Embedding Creation\n",
    "    def create_embeddings(self) -> None:\n",
    "        \"\"\"Create embeddings for all documents in knowledge base\"\"\"\n",
    "        if not self.use_embeddings:\n",
    "            return\n",
    "            \n",
    "        print(\"Creating embeddings for knowledge base...\")\n",
    "        self.doc_embeddings = []\n",
    "        \n",
    "        # Clear existing index\n",
    "        self.vector_index = faiss.IndexFlatIP(self.embedding_dim)\n",
    "        \n",
    "        for doc in self.knowledge_base:\n",
    "            embedding = self.embedding_model.encode([doc[\"full_text\"]])[0]\n",
    "            self.doc_embeddings.append(embedding)\n",
    "            \n",
    "        # Add all embeddings to Faiss index\n",
    "        if self.doc_embeddings:\n",
    "            embeddings_array = np.array(self.doc_embeddings, dtype=np.float32)\n",
    "            # Normalize for cosine similarity\n",
    "            faiss.normalize_L2(embeddings_array)\n",
    "            self.vector_index.add(embeddings_array)\n",
    "            \n",
    "        print(f\"Created {len(self.doc_embeddings)} embeddings\")\n",
    "\n",
    "    # NEW: Avoid Re-embedding / Cache Embeddings\n",
    "    def save_cached_embeddings(self) -> None:\n",
    "        \"\"\"Save embeddings to cache for faster loading\"\"\"\n",
    "        if not self.use_embeddings:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            # Save document embeddings and metadata\n",
    "            cache_data = {\n",
    "                'doc_embeddings': self.doc_embeddings,\n",
    "                'knowledge_base': self.knowledge_base\n",
    "            }\n",
    "            with open(self.cache_file, 'wb') as f:\n",
    "                pickle.dump(cache_data, f)\n",
    "                \n",
    "            # Save Faiss index\n",
    "            faiss.write_index(self.vector_index, self.vector_cache_file)\n",
    "            print(\"Embeddings cached successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving cache: {str(e)}\")\n",
    "\n",
    "    # NEW: Load cached embeddings\n",
    "    def load_cached_embeddings(self) -> None:\n",
    "        \"\"\"Load embeddings from cache to avoid re-computation\"\"\"\n",
    "        if not self.use_embeddings:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            if os.path.exists(self.cache_file) and os.path.exists(self.vector_cache_file):\n",
    "                # Load cached data\n",
    "                with open(self.cache_file, 'rb') as f:\n",
    "                    cache_data = pickle.load(f)\n",
    "                    \n",
    "                # Only use cache if knowledge base matches\n",
    "                if len(cache_data['knowledge_base']) == len(self.knowledge_base):\n",
    "                    self.doc_embeddings = cache_data['doc_embeddings']\n",
    "                    self.vector_index = faiss.read_index(self.vector_cache_file)\n",
    "                    print(\"Loaded embeddings from cache\")\n",
    "                    return\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Cache loading failed: {str(e)}\")\n",
    "            \n",
    "        # Create new embeddings if cache loading failed\n",
    "        self.create_embeddings()\n",
    "        self.save_cached_embeddings()\n",
    "\n",
    "    # NEW: Enhanced similarity calculation with embeddings\n",
    "    def calculate_similarity_embeddings(self, query: str, top_k: int = 3) -> List[Tuple[float, Dict]]:\n",
    "        \"\"\"Calculate semantic similarity using embeddings\"\"\"\n",
    "        if not self.use_embeddings:\n",
    "            return []\n",
    "            \n",
    "        # Create query embedding\n",
    "        query_embedding = self.embedding_model.encode([query])\n",
    "        query_embedding = np.array(query_embedding, dtype=np.float32)\n",
    "        faiss.normalize_L2(query_embedding)\n",
    "        \n",
    "        # Search in vector database\n",
    "        similarities, indices = self.vector_index.search(query_embedding, top_k)\n",
    "        \n",
    "        results = []\n",
    "        for i, (similarity, idx) in enumerate(zip(similarities[0], indices[0])):\n",
    "            if idx < len(self.knowledge_base):\n",
    "                results.append((float(similarity), self.knowledge_base[idx]))\n",
    "                \n",
    "        return results\n",
    "\n",
    "    # Original tokenization method (kept for fallback)\n",
    "    def simple_tokenize(self, text: str) -> List[str]:\n",
    "        \"\"\"Basic tokenization - split text into words\"\"\"\n",
    "        return text.lower().replace(',', '').replace('.', '').split()\n",
    "\n",
    "    # Enhanced similarity with semantic understanding\n",
    "    def calculate_similarity(self, query_words: List[str], doc_words: List[str]) -> float:\n",
    "        \"\"\"Calculate simple word overlap similarity (fallback method)\"\"\"\n",
    "        query_set = set(query_words)\n",
    "        doc_set = set(doc_words)\n",
    "        \n",
    "        if not query_set or not doc_set:\n",
    "            return 0.0\n",
    "            \n",
    "        intersection = len(query_set.intersection(doc_set))\n",
    "        union = len(query_set.union(doc_set))\n",
    "        \n",
    "        return intersection / union if union > 0 else 0.0\n",
    "\n",
    "    # NEW: Semantic Similarity (word variants)\n",
    "    def search_knowledge_base(self, query: str, top_k: int = 3) -> List[Dict]:\n",
    "        \"\"\"Enhanced search with semantic similarity\"\"\"\n",
    "        if self.use_embeddings:\n",
    "            # Use embedding-based semantic search\n",
    "            results = self.calculate_similarity_embeddings(query, top_k)\n",
    "            return [doc for score, doc in results if score > 0.3]  # Threshold for relevance\n",
    "        else:\n",
    "            # Fallback to original word-based search\n",
    "            query_words = self.simple_tokenize(query)\n",
    "            scored_docs = []\n",
    "            \n",
    "            for doc in self.knowledge_base:\n",
    "                doc_words = self.simple_tokenize(doc[\"content\"])\n",
    "                similarity = self.calculate_similarity(query_words, doc_words)\n",
    "                scored_docs.append((similarity, doc))\n",
    "                \n",
    "            scored_docs.sort(key=lambda x: x[0], reverse=True)\n",
    "            return [doc for score, doc in scored_docs[:top_k] if score > 0]\n",
    "\n",
    "    def generate_response(self, user_input: str) -> str:\n",
    "        \"\"\"Generate response using enhanced RAG approach\"\"\"\n",
    "        # Retrieve relevant documents using enhanced search\n",
    "        relevant_docs = self.search_knowledge_base(user_input, top_k=3)\n",
    "        \n",
    "        # Create context from retrieved documents\n",
    "        context = \"\"\n",
    "        for doc in relevant_docs:\n",
    "            context += doc[\"full_text\"] + \" \"\n",
    "            \n",
    "        # Generate response based on input and context\n",
    "        return self.create_response(user_input, context.strip(), relevant_docs)\n",
    "\n",
    "    def create_response(self, user_input: str, context: str, relevant_docs: List[Dict]) -> str:\n",
    "        \"\"\"Create enhanced response with document sources\"\"\"\n",
    "        user_lower = user_input.lower()\n",
    "        \n",
    "        # Enhanced response generation with category awareness\n",
    "        response = \"\"\n",
    "        categories_found = set()\n",
    "        \n",
    "        if relevant_docs:\n",
    "            for doc in relevant_docs:\n",
    "                categories_found.add(doc.get(\"category\", \"general\"))\n",
    "        \n",
    "        # Detect primary concern and provide targeted response\n",
    "        if any(word in user_lower for word in ['anxiety', 'anxious', 'worried', 'panic']):\n",
    "            response = \"I understand you're experiencing anxiety. \"\n",
    "            if 'anxiety' in categories_found:\n",
    "                response += context\n",
    "            response += \"\\n\\nWhat specific situations trigger your anxiety? Talking through them can help.\"\n",
    "            \n",
    "        elif any(word in user_lower for word in ['depression', 'depressed', 'sad', 'hopeless']):\n",
    "            response = \"I hear that you're going through a difficult time. \"\n",
    "            if 'depression' in categories_found:\n",
    "                response += context\n",
    "            response += \"\\n\\nHow long have you been feeling this way? Remember that seeking help shows strength.\"\n",
    "            \n",
    "        elif any(word in user_lower for word in ['stress', 'stressed', 'overwhelmed']):\n",
    "            response = \"Stress can feel overwhelming, but there are ways to manage it. \"\n",
    "            if 'stress' in categories_found:\n",
    "                response += context\n",
    "            response += \"\\n\\nWhat's the main source of stress in your life right now?\"\n",
    "            \n",
    "        elif any(word in user_lower for word in ['trauma', 'ptsd', 'flashback']):\n",
    "            response = \"Trauma can have lasting effects, but healing is possible. \"\n",
    "            if 'trauma' in categories_found:\n",
    "                response += context\n",
    "            response += \"\\n\\nTrauma therapy with qualified professionals can be very effective.\"\n",
    "            \n",
    "        elif any(word in user_lower for word in ['crisis', 'suicide', 'self-harm']):\n",
    "            response = \"I'm concerned about you. Please reach out for immediate support: \"\n",
    "            if 'crisis' in categories_found:\n",
    "                response += context\n",
    "            response += \"\\n\\nYour life has value. Please contact these resources right away.\"\n",
    "            \n",
    "        else:\n",
    "            if context:\n",
    "                response = \"I'm here to help with mental health support. \" + context\n",
    "            else:\n",
    "                response = \"I'm here to support you with mental health concerns like anxiety, depression, stress management, and crisis resources.\"\n",
    "            response += \"\\n\\nWhat's on your mind today? How can I best support you?\"\n",
    "        \n",
    "        # Add source information if using advanced mode\n",
    "        if self.use_embeddings and relevant_docs:\n",
    "            sources = set([doc.get('source', doc['id']) for doc in relevant_docs])\n",
    "            if len(sources) > 1:\n",
    "                response += f\"\\n\\n(Information from: {', '.join(list(sources)[:3])})\"\n",
    "                \n",
    "        return response\n",
    "\n",
    "    def chat(self, user_input: str) -> str:\n",
    "        \"\"\"Main chat function with enhanced capabilities\"\"\"\n",
    "        # Add to conversation history\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "        \n",
    "        # Generate response using enhanced RAG\n",
    "        response = self.generate_response(user_input)\n",
    "        \n",
    "        # Add response to history\n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "        \n",
    "        # Keep history manageable\n",
    "        if len(self.conversation_history) > 10:\n",
    "            self.conversation_history = self.conversation_history[-10:]\n",
    "            \n",
    "        return response\n",
    "\n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"Get system statistics\"\"\"\n",
    "        stats = {\n",
    "            \"Total Documents\": len(self.knowledge_base),\n",
    "            \"Conversation Length\": len(self.conversation_history),\n",
    "            \"Advanced Mode\": self.use_embeddings,\n",
    "        }\n",
    "        \n",
    "        if self.use_embeddings:\n",
    "            stats[\"Vector Database Size\"] = self.vector_index.ntotal\n",
    "            stats[\"Embedding Dimension\"] = self.embedding_dim\n",
    "            \n",
    "        return stats\n",
    "\n",
    "    # NEW: Batch document processing\n",
    "    def batch_ingest_documents(self, documents: List[Dict]) -> None:\n",
    "        \"\"\"Ingest multiple documents at once\"\"\"\n",
    "        for doc_info in documents:\n",
    "            self.ingest_document(\n",
    "                doc_info['text'], \n",
    "                doc_info['id'], \n",
    "                doc_info.get('category', 'general')\n",
    "            )\n",
    "        \n",
    "        # Update cache after batch processing\n",
    "        if self.use_embeddings:\n",
    "            self.save_cached_embeddings()\n",
    "\n",
    "def demo_enhanced_system():\n",
    "    \"\"\"Demonstrate the enhanced RAG system\"\"\"\n",
    "    print(\"ENHANCED RAG SYSTEM DEMONSTRATION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    assistant = EnhancedRAGAssistant()\n",
    "    \n",
    "    # Demo 1: Show knowledge base\n",
    "    print(\"Knowledge Base Topics:\")\n",
    "    categories = {}\n",
    "    for doc in assistant.knowledge_base:\n",
    "        category = doc.get('category', 'general')\n",
    "        if category not in categories:\n",
    "            categories[category] = 0\n",
    "        categories[category] += 1\n",
    "    \n",
    "    for category, count in categories.items():\n",
    "        print(f\"- {category}: {count} documents\")\n",
    "    \n",
    "    # Demo 2: Show enhanced search\n",
    "    print(\"\\nEnhanced Search Demonstration:\")\n",
    "    test_queries = [\n",
    "        \"I feel anxious about social situations\",\n",
    "        \"I'm having trouble sleeping and feel sad\",\n",
    "        \"work is overwhelming me\",\n",
    "        \"I keep having flashbacks\"\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        results = assistant.search_knowledge_base(query, top_k=2)\n",
    "        categories = [doc.get('category', 'unknown') for doc in results]\n",
    "        print(f\"Query: '{query}' -> Found: {categories}\")\n",
    "    \n",
    "    # Demo 3: Show complete enhanced pipeline\n",
    "    print(\"\\nEnhanced RAG Pipeline Test:\")\n",
    "    test_input = \"I've been having panic attacks and can't sleep\"\n",
    "    response = assistant.chat(test_input)\n",
    "    print(f\"Input: {test_input}\")\n",
    "    print(f\"Response: {response[:150]}...\")\n",
    "    \n",
    "    # Demo 4: Show stats\n",
    "    print(\"\\nSystem Statistics:\")\n",
    "    stats = assistant.get_stats()\n",
    "    for key, value in stats.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "def interactive_enhanced_chat():\n",
    "    \"\"\"Enhanced interactive chat with new features\"\"\"\n",
    "    print(\"\\nENHANCED MENTAL HEALTH ASSISTANT\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"Commands: 'quit' to exit, 'stats' for info, 'upload <pdf_path>' for PDF\")\n",
    "    print(\"'ingest <text>' to add custom content\")\n",
    "    \n",
    "    assistant = EnhancedRAGAssistant()\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"\\nYou: \").strip()\n",
    "            \n",
    "            if user_input.lower() in ['quit', 'exit']:\n",
    "                print(\"Take care of yourself!\")\n",
    "                break\n",
    "                \n",
    "            if user_input.lower() == 'stats':\n",
    "                stats = assistant.get_stats()\n",
    "                for key, value in stats.items():\n",
    "                    print(f\"{key}: {value}\")\n",
    "                continue\n",
    "                \n",
    "            # NEW: PDF upload command\n",
    "            if user_input.lower().startswith('upload '):\n",
    "                pdf_path = user_input[7:].strip()\n",
    "                assistant.upload_pdf(pdf_path)\n",
    "                continue\n",
    "                \n",
    "            # NEW: Custom document ingestion\n",
    "            if user_input.lower().startswith('ingest '):\n",
    "                text = user_input[7:].strip()\n",
    "                doc_id = f\"custom_{len(assistant.knowledge_base)}\"\n",
    "                assistant.ingest_document(text, doc_id, \"custom\")\n",
    "                print(f\"Added custom document: {doc_id}\")\n",
    "                continue\n",
    "                \n",
    "            if user_input:\n",
    "                response = assistant.chat(user_input)\n",
    "                print(f\"\\nAssistant: {response}\")\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nGoodbye!\")\n",
    "            break\n",
    "\n",
    "# For Jupyter notebook\n",
    "def start_enhanced_assistant():\n",
    "    \"\"\"Quick start for Jupyter with enhanced features\"\"\"\n",
    "    assistant = EnhancedRAGAssistant()\n",
    "    \n",
    "    def chat(message):\n",
    "        return assistant.chat(message)\n",
    "    \n",
    "    def upload_pdf(pdf_path):\n",
    "        return assistant.upload_pdf(pdf_path)\n",
    "    \n",
    "    def add_document(text, doc_id, category=\"custom\"):\n",
    "        return assistant.ingest_document(text, doc_id, category)\n",
    "    \n",
    "    def get_stats():\n",
    "        return assistant.get_stats()\n",
    "    \n",
    "    print(\"Enhanced Assistant ready!\")\n",
    "    print(\"Functions: chat('message'), upload_pdf('path'), add_document('text', 'id'), get_stats()\")\n",
    "    \n",
    "    return {\n",
    "        'chat': chat,\n",
    "        'upload_pdf': upload_pdf,\n",
    "        'add_document': add_document,\n",
    "        'get_stats': get_stats\n",
    "    }\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    demo_enhanced_system()\n",
    "    interactive_enhanced_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d22a8a-1e84-45fd-bb81-305439fad6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aab690-5aae-4c2c-b946-abd35d311ede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
